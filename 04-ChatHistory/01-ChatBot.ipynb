{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A Chatbot\n",
    "An example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This notebook will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1214193d0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x12141ad10>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a type of artificial intelligence (AI) that allows computers to learn from data without being explicitly programmed. \\n\\nHere\\'s a breakdown:\\n\\n**Instead of:**\\n\\n* **Being told exactly what to do** for every situation (like a traditional program),\\n\\n**Machine learning algorithms:**\\n\\n* **Identify patterns and relationships** in large datasets.\\n* **Use those patterns to make predictions or decisions** about new, unseen data.\\n\\n**Think of it like this:**\\n\\nImagine teaching a child to recognize a cat. You wouldn\\'t write a list of all the features that make a cat a cat (furry, four legs, whiskers, etc.). Instead, you\\'d show them lots of pictures of cats and say \"This is a cat.\" Over time, the child learns to recognize the patterns that define a cat and can identify new cats they haven\\'t seen before.\\n\\nMachine learning works in a similar way.\\n\\n**Types of Machine Learning:**\\n\\n* **Supervised Learning:** The algorithm is trained on labeled data (e.g., images labeled as \"cat\" or \"dog\"). It learns to map inputs to outputs.\\n* **Unsupervised Learning:** The algorithm is trained on unlabeled data and must find patterns and structures on its own (e.g., grouping customers with similar buying habits).\\n* **Reinforcement Learning:** The algorithm learns through trial and error, receiving rewards for correct actions and penalties for incorrect ones (e.g., training a game-playing AI).\\n\\n**Examples of Machine Learning in Action:**\\n\\n* **Recommendation systems:** Netflix suggesting movies you might like\\n* **Spam filtering:** Identifying and blocking unwanted emails\\n* **Fraud detection:** Identifying suspicious transactions\\n* **Medical diagnosis:** Assisting doctors in diagnosing diseases\\n* **Self-driving cars:** Navigating roads and avoiding obstacles\\n\\n\\nMachine learning is a powerful tool with the potential to revolutionize many industries.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 395, 'prompt_tokens': 14, 'total_tokens': 409, 'completion_time': 0.718181818, 'prompt_time': 9.135e-05, 'queue_time': 0.014064149, 'total_time': 0.718273168}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e34d197d-6ab6-48eb-a8a3-a75bae74e5ab-0', usage_metadata={'input_tokens': 14, 'output_tokens': 395, 'total_tokens': 409})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"What is machine learning?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The topic we are discussing now is **machine learning**.  \\n\\nI explained what it is, and you asked me to elaborate.  \\n\\nIs there anything else you'd like to know about machine learning?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 58, 'total_tokens': 103, 'completion_time': 0.081818182, 'prompt_time': 0.001736614, 'queue_time': 0.012193514999999999, 'total_time': 0.083554796}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-40e327b9-cda7-438c-913b-b8f6d8550a8a-0', usage_metadata={'input_tokens': 58, 'output_tokens': 45, 'total_tokens': 103})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(content=\"What is machine learning?\"),\n",
    "    AIMessage(content=\"Machine learning is a type of artificial intelligence (AI) that allows computers to learn from data without being explicitly programmed.\"),\n",
    "    HumanMessage(content=\"What's the topic being dicussed now?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine learning is a type of artificial intelligence (AI) that allows computers to learn from data without being explicitly programmed. \\n\\nHere\\'s a breakdown:\\n\\n**Instead of giving a computer specific instructions for every possible scenario, you feed it large amounts of data.** The machine then uses algorithms to identify patterns, relationships, and insights within that data. This allows it to make predictions or decisions on new, unseen data.\\n\\n**Think of it like this:**\\n\\n* **Traditional programming:** You write a recipe (code) that tells the computer exactly how to make a cake.\\n* **Machine learning:** You give the computer many pictures of cakes and tell it which ones are good and which ones are bad. The computer learns the features of a good cake and can then identify good cakes in new pictures.\\n\\n**Types of Machine Learning:**\\n\\n* **Supervised learning:** The algorithm is trained on labeled data (e.g., images labeled as \"cat\" or \"dog\").\\n* **Unsupervised learning:** The algorithm is trained on unlabeled data and must find patterns on its own (e.g., grouping customers based on their purchasing behavior).\\n* **Reinforcement learning:** The algorithm learns by interacting with its environment and receiving rewards or penalties for its actions (e.g., training a robot to navigate a maze).\\n\\n**Examples of Machine Learning in Action:**\\n\\n* **Recommendation systems:** Netflix suggesting movies you might like.\\n* **Spam filtering:** Identifying and blocking unwanted emails.\\n* **Fraud detection:** Identifying suspicious transactions.\\n* **Medical diagnosis:** Assisting doctors in diagnosing diseases.\\n* **Self-driving cars:** Navigating roads and making driving decisions.\\n\\n\\nMachine learning is a rapidly evolving field with the potential to transform many aspects of our lives.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat1\"}}\n",
    "\n",
    "response = with_message_history.invoke([HumanMessage(content=\"What is machine learning?\")], config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The topic we are discussing now is **machine learning**.  \\n\\nYou asked me to define it, and we've been going back and forth about its different types and examples.  üòä \\n\\n\\nWhat else would you like to know about machine learning?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 552, 'total_tokens': 606, 'completion_time': 0.098181818, 'prompt_time': 0.019663469, 'queue_time': 0.092835181, 'total_time': 0.117845287}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fd7de776-0918-435c-88ff-28ab5424adff-0', usage_metadata={'input_tokens': 552, 'output_tokens': 54, 'total_tokens': 606})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke([HumanMessage(content=\"What's the topic being dicussed now in this chat?\")], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I don't have memory of past conversations. Every interaction we have is a fresh start.\\n\\nWhat topic would you like to discuss? üòä\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config-->session id\n",
    "config1 = {\"configurable\": {\"session_id\": \"chat2\"}}\n",
    "\n",
    "response = with_message_history.invoke([HumanMessage(content=\"What's the topic being dicussed now in this chat?\")], config=config1)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all the question to the best of your ability.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Machine learning is a type of artificial intelligence (AI) that allows computers to learn from data without being explicitly programmed. \\n\\nHere's a breakdown:\\n\\n**Instead of giving a computer specific instructions for every possible scenario, machine learning algorithms are trained on large datasets.**  They identify patterns, relationships, and insights within the data, and use those learnings to make predictions or decisions on new, unseen data.\\n\\n**Think of it like this:**\\n\\n* **Traditional programming:** You tell the computer exactly what to do step-by-step.\\n* **Machine learning:** You give the computer data and let it figure out the rules and patterns on its own.\\n\\n**Types of Machine Learning:**\\n\\n* **Supervised learning:** The algorithm is trained on labeled data (data with known inputs and outputs). It learns to map inputs to outputs, allowing it to make predictions on new data.\\n* **Unsupervised learning:** The algorithm is trained on unlabeled data and must find patterns and structure on its own. This is often used for clustering, dimensionality reduction, and anomaly detection.\\n* **Reinforcement learning:** The algorithm learns through trial and error, receiving rewards for correct actions and penalties for incorrect ones. This is often used in robotics and game playing.\\n\\n**Examples of Machine Learning in Action:**\\n\\n* **Recommendation systems** (Netflix, Amazon)\\n* **Spam filtering**\\n* **Image recognition** (self-driving cars, facial recognition)\\n* **Fraud detection**\\n* **Medical diagnosis**\\n\\n**Key Takeaways:**\\n\\n* Machine learning enables computers to learn from data and make intelligent decisions.\\n* It's a powerful tool with a wide range of applications.\\n* There are different types of machine learning, each suited to different tasks.\\n\\n\\nLet me know if you have any more questions!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 374, 'prompt_tokens': 31, 'total_tokens': 405, 'completion_time': 0.68, 'prompt_time': 0.000562858, 'queue_time': 0.012595341000000001, 'total_time': 0.680562858}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-157cbec0-4ae1-49e9-9b31-a96531dabbe1-0', usage_metadata={'input_tokens': 31, 'output_tokens': 374, 'total_tokens': 405})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\": [HumanMessage(content=\"What is machine learning?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Machine learning is a type of artificial intelligence (AI) that allows computers to learn from data without being explicitly programmed. \\n\\nHere\\'s a breakdown:\\n\\n**Instead of giving computers specific instructions for every scenario, we feed them large amounts of data and let them identify patterns and relationships.**  \\n\\nThink of it like teaching a child to recognize a cat. You wouldn\\'t write a program with every possible feature of a cat (whiskers, pointy ears, furry, etc.). Instead, you\\'d show them many pictures of cats, and they\\'d learn to identify the common characteristics.\\n\\n**Machine learning algorithms** are the \"students\" in this scenario. They analyze the data, adjust their internal parameters, and improve their ability to make predictions or decisions based on new, unseen data.\\n\\n**There are different types of machine learning:**\\n\\n* **Supervised learning:** The algorithm is trained on labeled data (e.g., images labeled \"cat\" or \"not cat\"). It learns to map inputs to outputs.\\n* **Unsupervised learning:** The algorithm is trained on unlabeled data and must find patterns and structures on its own (e.g., clustering customers with similar purchasing habits).\\n* **Reinforcement learning:** The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions (e.g., training a game-playing AI).\\n\\n**Machine learning is used in a wide range of applications:**\\n\\n* **Image recognition and classification**\\n* **Natural language processing (e.g., chatbots, language translation)**\\n* **Recommendation systems (e.g., Netflix, Amazon)**\\n* **Fraud detection**\\n* **Medical diagnosis**\\n* **Self-driving cars**\\n\\n\\nLet me know if you have any other questions!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 367, 'prompt_tokens': 31, 'total_tokens': 398, 'completion_time': 0.667272727, 'prompt_time': 0.000362918, 'queue_time': 0.014283491, 'total_time': 0.667635645}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1131fa6a-5730-43ea-928a-4139220e87f6-0', usage_metadata={'input_tokens': 31, 'output_tokens': 367, 'total_tokens': 398})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "\n",
    "response = with_message_history.invoke([HumanMessage(content=\"What is machine learning?\")], config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The topic we're discussing is **machine learning**.  \\n\\nI explained what it is, the different types, and some of its applications. \\n\\nDo you have any more questions about it? üòä  \\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke([HumanMessage(content=\"What's the topic being dicussed now in this chat?\")], config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\"), \n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡Æ™‡ØÅ‡Æ±‡Æ®‡Æø‡Æ≤‡Øà‡Æ™‡Øç ‡Æ™‡Æ∞‡Æ™‡Øç‡Æ™‡Æø‡Æ©‡Øç ‡ÆÖ‡Æü‡Æø‡Æ™‡Øç‡Æ™‡Æü‡Øà‡ÆØ‡Æø‡Æ≤‡Øç ‡Æâ‡Æ≤‡Æï‡Æø‡Æ©‡Øç ‡ÆÆ‡Æø‡Æï‡Æ™‡Øç‡Æ™‡ØÜ‡Æ∞‡Æø‡ÆØ ‡Æ®‡Æï‡Æ∞‡ÆÆ‡Øç **‡Æü‡Øã‡Æï‡Øç‡Æï‡Æø‡ÆØ‡Øã** ‡ÆÜ‡Æï‡ØÅ‡ÆÆ‡Øç. \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\": [HumanMessage(content=\"What's the largest city in the world based on the area?\")], \"language\": \"Tamil\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æú‡Ææ‡Æ©‡Øç! ‡Æ®‡Ææ‡Æ©‡Øç ‡Æ®‡Æ©‡Øç‡Æ±‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç. ‡Æ®‡ØÄ ‡Æé‡Æ™‡Øç‡Æ™‡Æü‡Æø ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Ææ‡ÆØ‡Øç? üòä \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "repsonse = with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"John here, how are you?\")], \"language\": \"Tamil\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç ‡Æú‡Ææ‡Æ©‡Øç.  üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 79, 'total_tokens': 93, 'completion_time': 0.025454545, 'prompt_time': 0.002550381, 'queue_time': 0.012162926000000001, 'total_time': 0.028004926}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bc70fc61-2ddc-4de7-bcea-87122ed7032e-0', usage_metadata={'input_tokens': 79, 'output_tokens': 14, 'total_tokens': 93})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What's my name?\")], \"language\": \"Tamil\"},\n",
    "    config=config,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kamaraj/scm/ai/genai-langchain/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/kamaraj/scm/ai/genai-langchain/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"what's 2 + 2\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a good assistant\"),\n",
    "    HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"what's 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a helpful assistant, I don't have personal preferences or memories, so I don't know what ice cream you like! \\n\\nWhat's your favorite flavor? üòÑüç¶  \\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do I like?\")],\n",
    "    \"language\":\"English\"\n",
    "})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"What is 2 + 2?\"  \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"what math problem did I ask?\")],\n",
    "    \"language\": \"English\",\n",
    "})\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
